{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips\n",
    "data operation (clean, transform) not only on master node, split them at first to all nodes\n",
    "- split process from beginning and check the cpu consumption of each step\n",
    "\n",
    "should be better on some algorithm like k-fold (faster by parallel computing): \n",
    "- do it!!\n",
    "- use gather to create train or just bcast all data on each node at first\n",
    "\n",
    "find a better way to measure CPU rather than fork        \n",
    "- multipleprocess\n",
    "\n",
    "save latency and cpu measure as a function can be imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MPI Random Forest Classifier - Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "# data frame operation\n",
    "import numpy as np\n",
    "# latency timer\n",
    "\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MPI_rf():\n",
    "    # mpi4py: MPI.COMM_WORLD: communicator including all nodes\n",
    "    #.Get_rank()/.Get_size()\n",
    "    comm = MPI.COMM_WORLD \n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    # for recording\n",
    "    file_name = \"./\" + str(dt.datetime.now().strftime('%d%H%M')) +\"_mpi_sklearn_rf_\"\n",
    "    # for node 1-8, 1680!\n",
    "    L = 1680 # length before scatter\n",
    "    l = int(L / size) # length after scatter\n",
    "    # on all nodes, create variables for later use\n",
    "    X_train = None\n",
    "    Y_train = None\n",
    "    Pred = None\n",
    "    \n",
    "    # on master, import/transform datas\n",
    "    if rank == 0:\n",
    "        # Load data from a text file, specify seperator as ','\n",
    "        train = np.genfromtxt('temptrain.csv', delimiter=',')\n",
    "        ## ?? train1 = train.reshape(157774)\n",
    "        # subset a sample\n",
    "        samples = 2000\n",
    "        sample = train[1:samples]\n",
    "        \n",
    "        d1 = sample[0:samples-3]\n",
    "        d2 = sample[1:samples-2]\n",
    "        d3 = sample[2:samples-1]\n",
    "        # .reshape(-1, 1) change shape to one column(do not specify row)\n",
    "        # np.concatenate((arr1, arr2,...), axis=1): append arrays by row\n",
    "        X_train = np.concatenate((d1.reshape(-1,1),\n",
    "                                  d2.reshape(-1,1),\n",
    "                                  d3.reshape(-1,1)),axis=1)\n",
    "        Y_train = sample[2:samples]\n",
    "        # Y_train = Y_train.T\n",
    "        \n",
    "        #confirm number of nodes\n",
    "        print(\"\\n\"+str(size)+\"\\n\\n\")\n",
    "        # data to be scatterd\n",
    "        X_train = X_train[:L,:]  \n",
    "        Y_train = Y_train[:L]\n",
    "        # create to gather data\n",
    "        Pred = np.zeros([l, size])\n",
    "        \n",
    "    # create to received data on each processl\n",
    "    part_x = np.zeros([l,3])\n",
    "    part_y = np.zeros(l) \n",
    "    \n",
    "    # timer for communication and modelling\n",
    "    t_start = MPI.Wtime()\n",
    "    # scatter to each process\n",
    "    comm.Scatter(X_train, part_x, root = 0) \n",
    "    comm.Scatter(Y_train, part_y, root = 0) \n",
    "    #define fit model\n",
    "    rfc = RandomForestClassifier(max_depth= 6, min_samples_leaf=9, \n",
    "                                 n_estimators = 50, \n",
    "                                 min_samples_split=15, \n",
    "                                 max_features=0.6, oob_score=True)\n",
    "    rfc.fit(part_x, part_y) \n",
    "    pred = rfc.predict(part_x)\n",
    "    # gather pred to process 0\n",
    "    comm.Gather(pred, Pred, root=0)\n",
    "    # modeling done\n",
    "    t_end = MPI.Wtime()\n",
    "    latency = t_end - t_start\n",
    "    \n",
    "    # record latency on each node\n",
    "    file = open(file_name+\"latency.txt\", \"a\") \n",
    "    file.write('%d,%d,%20.4f\\n' % (size, rank, latency))\n",
    "    # Evaluation\n",
    "    if rank == 0 :\n",
    "        score = f1_score(Y_train, Pred.reshape(L), average='micro')\n",
    "        # open(file, mode='a'): open for writing, appending\n",
    "        file = open(file_name+\"score.txt\", \"a\") \n",
    "        file.write('%d, %f\\n' % (size, score))\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this file is executed directly, run MPI_rf()                \n",
    "if __name__ == '__main__':\n",
    "    MPI_rf()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\r\n",
      "Open MPI has detected that a parameter given to a command line\r\n",
      "option does not match the expected format:\r\n",
      "\r\n",
      "  Option: n\r\n",
      "  Param:  {1..8}\r\n",
      "\r\n",
      "This is frequently caused by omitting to provide the parameter\r\n",
      "to an option that requires one. Please check the command line and try again.\r\n",
      "----------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!for i in {1..8}; do mpiexec -n $i python MPI_rf_latency.py; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MPI Random Forest Classifer - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import f1_score\n",
    "from os import fork\n",
    "from os import kill \n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import time \n",
    "import csv \n",
    "#psutil: process and system utilities\n",
    "import psutil\n",
    "import signal\n",
    "\n",
    "#import ctypes\n",
    "#libc = ctypes.CDLL('libc.so.6') \n",
    "\n",
    "def cpu(file_name, node, size):\n",
    "    #cpu count\n",
    "    #cores = psutil.cpu_count()\n",
    "    cpu_file = open(file_name+str(node)+\"_cpu.txt\", \"a\")\n",
    "    #cpu_file.write('#Number of processes : %d\\n'%(size))\n",
    "    while 1:\n",
    "        # cpu used percent\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        #virtual memory info: total, available, percent, used, free, active\n",
    "        memory_percent = psutil.virtual_memory()[2]\n",
    "        #disk usage info: total, used, free, percent\n",
    "        disk_percent = psutil.disk_usage('/')[3]\n",
    "        # package counts\n",
    "        net_io_count = psutil.net_io_counters(pernic=True)\n",
    "        time.sleep(0.01) \n",
    "        cpu_file.write('%d,%2.2f,%2.2f,%2.2f\\n'\n",
    "                       %(size, cpu_percent, memory_percent, disk_percent))  \n",
    "\n",
    "def getSize():\n",
    "    iris = datasets.load_iris() \n",
    "    return len(iris.data)  \n",
    "\n",
    "def MPI_temp():\n",
    "    comm = MPI.COMM_WORLD \n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    # for node 1-8, 1680!\n",
    "    L = 84000 # length before scatter\n",
    "    l = int(L / size) # length after scatter\n",
    "    # on all nodes, create variables for later use\n",
    "    X_train = None\n",
    "    Y_train = None\n",
    "    Pred = None\n",
    "    stop = 0\n",
    "    file_name = \"./sample\"+str(L)+\"_mpi_sklearn_rf_\" \n",
    "    \n",
    "    if rank == 0:       \n",
    "        # Load data from a text file, specify seperator as ','\n",
    "        train = np.genfromtxt('temptrain.csv', delimiter=',')\n",
    "        ## ?? train1 = train.reshape(157774)\n",
    "        samples = 100000\n",
    "        sample1 = train[1:samples]\n",
    "    \n",
    "        d1 = sample1[0:samples-3]\n",
    "        d2 = sample1[1:samples-2]\n",
    "        d3 = sample1[2:samples-1]\n",
    "        # .reshape(-1, 1) change shape to one column(do not specify row)\n",
    "        # np.concatenate((arr1, arr2,...), axis=1): append arrays by row\n",
    "        X_train = np.concatenate((d1.reshape(-1,1),\n",
    "                                  d2.reshape(-1,1),\n",
    "                                  d3.reshape(-1,1)),axis=1)\n",
    "        Y_train = sample1[2:samples]\n",
    "        #Y_train = Y_train.T\n",
    "        print(\"\\n\"+str(size)+\"\\n\\n\")\n",
    "        X_train = X_train[:L,:]  \n",
    "        Y_train = Y_train[:L] \n",
    "        Pred = np.zeros([l, size])\n",
    "        \n",
    "    # define received data on each process(according to size)\n",
    "    part_x = np.zeros([l,3])\n",
    "    part_y = np.zeros(l) \n",
    "    \n",
    "    # fork() copy a process\n",
    "    newpid = fork()\n",
    "    # only on child process(fork() returns 0) of rank 0, call cup()\n",
    "    if newpid == 0:\n",
    "        libc.prctl(1, 15) \n",
    "        cpu(file_name, rank, size)\n",
    "        raise SystemExit\n",
    "    # on parent process(fork() returns new ID of process)\n",
    "    else: \n",
    "        t_start = MPI.Wtime()\n",
    "        comm.Scatter(X_train, part_x, root = 0) \n",
    "        comm.Scatter(Y_train, part_y, root = 0)       \n",
    "        clf = RandomForestClassifier(max_depth= 6, min_samples_leaf=9,\n",
    "                                     n_estimators = 50,\n",
    "                                     min_samples_split=15,\n",
    "                                     max_features=0.6, oob_score=True)\n",
    "        clf.fit(part_x, part_y) \n",
    "        pred = clf.predict(part_x) \n",
    "        comm.Gather(pred, Pred, root=0)\n",
    "        t_end = MPI.Wtime()\n",
    "        latency = t_end - t_start\n",
    "        # record latency on each node\n",
    "        file = open(file_name+\"latency.txt\", \"a\") \n",
    "        file.write('%d,%d,%.4f\\n' % (size, rank, latency))\n",
    "        if rank == 0:\n",
    "            score = f1_score(Y_train, Pred.reshape(L), average='micro')\n",
    "            # open(file, mode='a'): open for writing, appending\n",
    "            file = open(file_name+\"score.txt\", \"a\") \n",
    "            file.write('%d, %f\\n' % (size, score))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MPI_temp()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
